syntax = "proto3";

package llmoperator.batch.server.v1;

import "google/api/annotations.proto";

option go_package = "github.com/llm-operator/job-manager/api/v1";

message BatchJob {
  string id = 1;

  int64 created_at = 2;
  int64 finished_at = 3;

  message Error {
    string code = 1;
    string message = 2;
  }
  Error error = 4;
  string status = 5;

  string image = 6;
  string command = 7;

  message Resources {
    int32 gpu_count = 1;
  }
  Resources resources = 8;
  map<string, string> envs = 9;
  repeated string data_files = 10;
}

message CreateBatchJobRequest {
  string image = 1;
  string command = 2;
  // scripts is a map of script names to script contents.
  // The total size of the scripts should not exceed 1MB.
  map<string, bytes> scripts = 3;

  BatchJob.Resources resources = 4;
  map<string, string> envs = 5;
  // data_files is a list of file IDs that will be downloaded to the container.
  repeated string data_files = 6;
}

message ListBatchJobsRequest {
  // after is the identifier for the last batch job from the previous pagination request.
  string after = 1;
  // limit is the number of batch jobs to retrieve. Defaults to 20.
  int32 limit = 2;
}

message ListBatchJobsResponse {
  repeated BatchJob jobs = 1;
  bool has_more = 2;
}

message GetBatchJobRequest {
  string id = 1;
}

message CancelBatchJobRequest {
  string id = 1;
}

service BatchService {
  rpc CreateBatchJob(CreateBatchJobRequest) returns (BatchJob) {
    option (google.api.http) = {
      post: "/v1/batch/jobs"
      body: "*"
    };
  }
  rpc ListBatchJobs(ListBatchJobsRequest) returns (ListBatchJobsResponse) {
    option (google.api.http) = {
      get: "/v1/batch/jobs"
    };
  }
  rpc GetBatchJob(GetBatchJobRequest) returns (BatchJob) {
    option (google.api.http) = {
      get: "/v1/batch/jobs/{id}"
    };
  }
  rpc CancelBatchJob(CancelBatchJobRequest) returns (BatchJob) {
    option (google.api.http) = {
      post: "/v1/batch/jobs/{id}/cancel"
    };
  }
}
